{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460c7da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "import pandas as pd\n",
    "import collections\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "file_path = \"path-Sentiment_Analysis.csv\"\n",
    "try:\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(\"Data loaded successfully. First 5 rows:\")\n",
    "    display(data.head())\n",
    "except Exception as e:\n",
    "    print(f\"Error loading file: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\nAvailable columns:\", data.columns.tolist())\n",
    "\n",
    "column_mapping = {\n",
    "    'text': ['text', 'sentence', 'review', 'tweet', 'comment', 'phrase', 'content'],\n",
    "    'sentiment': ['sentiment', 'label', 'category', 'class', 'rating', 'emotion']\n",
    "}\n",
    "\n",
    "text_col = next((col for col in data.columns\n",
    "                if any(kw in col.lower() for kw in column_mapping['text'])), None)\n",
    "\n",
    "sentiment_col = next((col for col in data.columns\n",
    "                     if any(kw in col.lower() for kw in column_mapping['sentiment'])), None)\n",
    "\n",
    "if not text_col or not sentiment_col:\n",
    "    text_col, sentiment_col = data.columns[:2]\n",
    "    print(f\"\\n Using first two columns as: Text='{text_col}', Sentiment='{sentiment_col}'\")\n",
    "else:\n",
    "    print(f\"\\n Auto-detected columns: Text='{text_col}', Sentiment='{sentiment_col}'\")\n",
    "\n",
    "print(\"\\nBuilding sentiment graph...\")\n",
    "graph = collections.defaultdict(list)\n",
    "\n",
    "sentiment_groups = data.groupby(sentiment_col)[text_col].apply(list)\n",
    "\n",
    "for sentiment, sentences in sentiment_groups.items():\n",
    "    for i in range(len(sentences)):\n",
    "        for j in range(i+1, len(sentences)):\n",
    "            graph[sentences[i]].append(sentences[j])\n",
    "            graph[sentences[j]].append(sentences[i])\n",
    "\n",
    "print(f\"Graph built with {len(graph)} nodes\")\n",
    "\n",
    "def bfs(graph, start_node):\n",
    "    if start_node not in graph:\n",
    "        raise ValueError(f\"Start node not found in graph: '{start_node}'\")\n",
    "\n",
    "    visited = set()\n",
    "    queue = collections.deque([start_node])\n",
    "    visited.add(start_node)\n",
    "    traversal_order = [start_node]\n",
    "\n",
    "    while queue:\n",
    "        current_node = queue.popleft()\n",
    "        for neighbor in graph.get(current_node, []):\n",
    "            if neighbor not in visited:\n",
    "                visited.add(neighbor)\n",
    "                queue.append(neighbor)\n",
    "                traversal_order.append(neighbor)\n",
    "\n",
    "    return traversal_order\n",
    "\n",
    "start_node = data[text_col].iloc[0]\n",
    "print(f\"\\nStarting BFS with node: '{start_node[:50]}...'\")\n",
    "\n",
    "try:\n",
    "    traversal_order = bfs(graph, start_node)\n",
    "    print(f\"\\nBFS traversal completed. Visited {len(traversal_order)} nodes.\")\n",
    "    print(\"\\nFirst 5 nodes in traversal order:\")\n",
    "    for i, node in enumerate(traversal_order[:5], 1):\n",
    "        print(f\"{i}. {node[:70]}...\")\n",
    "except ValueError as e:\n",
    "    print(f\"\\nError: {e}\")\n",
    "    print(\"Available nodes sample:\", list(graph.keys())[:3])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
